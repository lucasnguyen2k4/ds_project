{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from ds_code.function.utils import sliding_window\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim import Adam\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1704774326</th>\n",
       "      <td>10.7756</td>\n",
       "      <td>106.7019</td>\n",
       "      <td>1.513600e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704413791</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>105.8500</td>\n",
       "      <td>8.246600e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704000623</th>\n",
       "      <td>20.8651</td>\n",
       "      <td>106.6838</td>\n",
       "      <td>2.103500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704783472</th>\n",
       "      <td>10.0333</td>\n",
       "      <td>105.7833</td>\n",
       "      <td>1.237300e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704863046</th>\n",
       "      <td>10.9500</td>\n",
       "      <td>106.8167</td>\n",
       "      <td>1.104000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704495953</th>\n",
       "      <td>22.8333</td>\n",
       "      <td>104.9833</td>\n",
       "      <td>5.555900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704000217</th>\n",
       "      <td>22.1333</td>\n",
       "      <td>105.8333</td>\n",
       "      <td>4.503600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704983526</th>\n",
       "      <td>22.3992</td>\n",
       "      <td>103.4392</td>\n",
       "      <td>4.297300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704988146</th>\n",
       "      <td>14.3544</td>\n",
       "      <td>108.0075</td>\n",
       "      <td>6.586050e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704949870</th>\n",
       "      <td>16.0748</td>\n",
       "      <td>108.2240</td>\n",
       "      <td>6.586050e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                lat       lng    population\n",
       "id                                         \n",
       "1704774326  10.7756  106.7019  1.513600e+07\n",
       "1704413791  21.0000  105.8500  8.246600e+06\n",
       "1704000623  20.8651  106.6838  2.103500e+06\n",
       "1704783472  10.0333  105.7833  1.237300e+06\n",
       "1704863046  10.9500  106.8167  1.104000e+06\n",
       "...             ...       ...           ...\n",
       "1704495953  22.8333  104.9833  5.555900e+04\n",
       "1704000217  22.1333  105.8333  4.503600e+04\n",
       "1704983526  22.3992  103.4392  4.297300e+04\n",
       "1704988146  14.3544  108.0075  6.586050e+05\n",
       "1704949870  16.0748  108.2240  6.586050e+05\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_data = pd.read_csv(\"data/region/vietnam/extra_info.csv\", index_col=0)\n",
    "city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_np = []\n",
    "air_np = []\n",
    "init_np = []\n",
    "\n",
    "for city_id in city_data.index:           #fix this\n",
    "    air_df = pd.read_csv(\"data/air_quality/\" + str(city_id) + \".csv\")\n",
    "    weather_df = pd.read_csv(\"data/weather/\" + str(city_id) + \".csv\")\n",
    "    \n",
    "    air_df = air_df.loc[(air_df.iloc[:, 1:] >= 0).all(axis=1)]\n",
    "    air_df.drop(\"aqi\", axis=1, inplace=True)\n",
    "    air_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    weather_df.dropna(axis=0, inplace=True)\n",
    "    weather_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    weather_df[\"wind_x_component\"] = np.cos(weather_df[\"wind_direction_10m\"])\n",
    "    weather_df[\"wind_y_component\"] = np.sin(weather_df[\"wind_direction_10m\"])\n",
    "    weather_df.drop(\"wind_direction_10m\", axis=1, inplace=True)\n",
    "    \n",
    "    X, y = sliding_window(weather_df, air_df, target_size=\"same\")\n",
    "    m = X.shape[0]\n",
    "    extra_attr = city_data.loc[city_id]\n",
    "    lat = np.full((m, 1), extra_attr[0])\n",
    "    lng = np.full((m, 1), extra_attr[1])\n",
    "    population = np.full((m, 1), extra_attr[2])\n",
    "    init_data = np.hstack((lat, lng, population))\n",
    "    \n",
    "    weather_np.append(X)\n",
    "    air_np.append(y)\n",
    "    init_np.append(init_data)\n",
    "    \n",
    "weather_np = np.vstack(weather_np)\n",
    "air_np = np.vstack(air_np)\n",
    "init_np = np.vstack(init_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gru_raw_dataset.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dump((weather_np, air_np, init_np), \"gru_raw_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_np, air_np, init_np = load(\"gru_raw_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StandardScaler, self).__init__()\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean = X.mean(dim=0, keepdim=True)\n",
    "        self.std = X.std(dim=0, keepdim=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return (X - self.mean) / self.std\n",
    "\n",
    "    def inverse_transform(self, X_scaled):\n",
    "        return X_scaled * self.std + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y, init_data, label_scaler=None):\n",
    "        self.X = Tensor(X)\n",
    "        self.y = Tensor(y)\n",
    "        self.init_data = Tensor(init_data)\n",
    "        \n",
    "        if label_scaler is not None:\n",
    "            self.scaler = label_scaler\n",
    "            self.scaler.fit(self.y)\n",
    "            self.y = label_scaler(self.y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.init_data[index]), self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGRU(nn.Module):\n",
    "    def __init__(self, input_size, output_size, seq_len=4, label_scaler=None):\n",
    "        super(CustomGRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.seq_len = seq_len\n",
    "        self.label_scaler = label_scaler\n",
    "        \n",
    "        self.init_nn = nn.Sequential(\n",
    "            nn.LayerNorm(3),\n",
    "            nn.Linear(3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),  # Generate initial hidden state\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten(1, -1)\n",
    "        self.normalize = nn.LayerNorm(input_size * seq_len)\n",
    "        self.gru1 = nn.GRU(input_size, 256, batch_first=True)\n",
    "        self.gru2 = nn.GRU(256, 128, batch_first=True)\n",
    "        self.gru3 = nn.GRU(128, 64, batch_first=True)\n",
    "        self.linear = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, inp, rescale=False):\n",
    "        X, init_data = inp\n",
    "        X = self.flatten(X)\n",
    "        X = self.normalize(X).reshape((-1, self.seq_len, self.input_size))\n",
    "        init_data = self.init_nn(init_data.unsqueeze(0))\n",
    "        X, _ = self.gru1(X, init_data)\n",
    "        X, _ = self.gru2(X)\n",
    "        X, _ = self.gru3(X)\n",
    "        X = self.linear(X)\n",
    "        if rescale:\n",
    "            X = self.label_scaler.inverse_transform(X)\n",
    "        return X\n",
    "    \n",
    "    def predict(self, inp, numpy_output=True):\n",
    "        X, init_data = inp\n",
    "        inp = (Tensor(X), Tensor(init_data))\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            output = self(inp, rescale=True)\n",
    "        if numpy_output:\n",
    "            output = output.numpy()\n",
    "        return output[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, valid_dataloader, learning_rate=1e-3, num_epochs=10):\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, patience=5)\n",
    "    criterion = nn.MSELoss()\n",
    "    val_patience = 20\n",
    "    waited_epoch = 0\n",
    "    best_val_loss = 9999\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "        for i, (X, y) in enumerate(train_dataloader):\n",
    "            X = X[0].to(device), X[1].to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            output = model(X)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(output, y)\n",
    "            total_loss += loss\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print(f\"Batch {i + 1}:\", f\"Loss: {total_loss / i:.4f}\")\n",
    "\n",
    "        print(f\"Training loss: {total_loss / len(train_dataloader):.4f}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            for X, y in valid_dataloader:\n",
    "                X = X[0].to(device), X[1].to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                output = model(X)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(output[:, -1], y[:, -1])\n",
    "                total_loss += loss\n",
    "            scheduler.step(total_loss)\n",
    "            \n",
    "        print(f\"Validaton loss: {total_loss / len(valid_dataloader):.4f}\\n\")\n",
    "            \n",
    "        if total_loss < best_val_loss:\n",
    "            waited_epoch = 0\n",
    "            best_val_loss = total_loss\n",
    "            torch.save(model, \"models/gru.pth\")\n",
    "        else:\n",
    "            waited_epoch += 1\n",
    "            if waited_epoch == val_patience:\n",
    "                print(\"Training stopped.\")\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X, init_data, rescale=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_np = weather_np.astype(\"float32\")\n",
    "air_np = air_np.astype(\"float32\")\n",
    "init_np = init_np.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "idx = [i for i in range(len(weather_np))]\n",
    "random.shuffle(idx)\n",
    "train_idx, test_idx = idx[:1800000], idx[1800000:]\n",
    "X_train, X_test, y_train, y_test, init_train, init_test = weather_np[train_idx], weather_np[test_idx], air_np[train_idx], air_np[test_idx], init_np[train_idx], init_np[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaler = StandardScaler()\n",
    "valid_scaler = StandardScaler()\n",
    "train_dataset = TimeSeriesDataset(X_train[:1700000], y_train[:1700000], init_train[:1700000], train_scaler)\n",
    "valid_dataset = TimeSeriesDataset(X_train[1700000:], y_train[1700000:], init_train[1700000:], valid_scaler)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomGRU(\n",
       "  (label_scaler): StandardScaler()\n",
       "  (init_nn): Sequential(\n",
       "    (0): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=3, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (normalize): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "  (gru1): GRU(9, 256, batch_first=True)\n",
       "  (gru2): GRU(256, 128, batch_first=True)\n",
       "  (gru3): GRU(128, 64, batch_first=True)\n",
       "  (linear): Linear(in_features=64, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = CustomGRU(9, 6, 4, label_scaler=train_scaler)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 1.0024\n",
      "Validaton loss: 0.9818\n",
      "\n",
      "Epoch 2/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9957\n",
      "Validaton loss: 0.9784\n",
      "\n",
      "Epoch 3/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 1.0086\n",
      "Validaton loss: 0.9665\n",
      "\n",
      "Epoch 4/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9717\n",
      "Validaton loss: 0.9831\n",
      "\n",
      "Epoch 5/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9665\n",
      "Validaton loss: 0.9327\n",
      "\n",
      "Epoch 6/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9364\n",
      "Validaton loss: 0.9256\n",
      "\n",
      "Epoch 7/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9351\n",
      "Validaton loss: 0.9331\n",
      "\n",
      "Epoch 8/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9300\n",
      "Validaton loss: 0.9721\n",
      "\n",
      "Epoch 9/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9270\n",
      "Validaton loss: 0.9240\n",
      "\n",
      "Epoch 10/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9205\n",
      "Validaton loss: 0.9169\n",
      "\n",
      "Epoch 11/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9220\n",
      "Validaton loss: 0.9308\n",
      "\n",
      "Epoch 12/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9122\n",
      "Validaton loss: 0.9427\n",
      "\n",
      "Epoch 13/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9154\n",
      "Validaton loss: 0.9136\n",
      "\n",
      "Epoch 14/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9146\n",
      "Validaton loss: 1.0889\n",
      "\n",
      "Epoch 15/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9030\n",
      "Validaton loss: 0.9560\n",
      "\n",
      "Epoch 16/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9083\n",
      "Validaton loss: 0.9175\n",
      "\n",
      "Epoch 17/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8958\n",
      "Validaton loss: 0.8939\n",
      "\n",
      "Epoch 18/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8977\n",
      "Validaton loss: 0.9874\n",
      "\n",
      "Epoch 19/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9001\n",
      "Validaton loss: 0.9046\n",
      "\n",
      "Epoch 20/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8878\n",
      "Validaton loss: 0.8769\n",
      "\n",
      "Epoch 21/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8821\n",
      "Validaton loss: 0.9204\n",
      "\n",
      "Epoch 22/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9141\n",
      "Validaton loss: 0.9844\n",
      "\n",
      "Epoch 23/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8871\n",
      "Validaton loss: 0.8786\n",
      "\n",
      "Epoch 24/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.9016\n",
      "Validaton loss: 0.9791\n",
      "\n",
      "Epoch 25/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8854\n",
      "Validaton loss: 0.8623\n",
      "\n",
      "Epoch 26/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8944\n",
      "Validaton loss: 0.8516\n",
      "\n",
      "Epoch 27/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8956\n",
      "Validaton loss: 1.0748\n",
      "\n",
      "Epoch 28/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8903\n",
      "Validaton loss: 0.9025\n",
      "\n",
      "Epoch 29/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8675\n",
      "Validaton loss: 0.9029\n",
      "\n",
      "Epoch 30/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8765\n",
      "Validaton loss: 0.9167\n",
      "\n",
      "Epoch 31/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8792\n",
      "Validaton loss: 0.8937\n",
      "\n",
      "Epoch 32/200\n",
      "Learning rate: 0.001\n",
      "Training loss: 0.8655\n",
      "Validaton loss: 0.8814\n",
      "\n",
      "Epoch 33/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8571\n",
      "Validaton loss: 0.8725\n",
      "\n",
      "Epoch 34/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8588\n",
      "Validaton loss: 0.8505\n",
      "\n",
      "Epoch 35/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8541\n",
      "Validaton loss: 0.9167\n",
      "\n",
      "Epoch 36/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8555\n",
      "Validaton loss: 0.8519\n",
      "\n",
      "Epoch 37/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8533\n",
      "Validaton loss: 0.8422\n",
      "\n",
      "Epoch 38/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8546\n",
      "Validaton loss: 0.8469\n",
      "\n",
      "Epoch 39/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8597\n",
      "Validaton loss: 0.8686\n",
      "\n",
      "Epoch 40/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8688\n",
      "Validaton loss: 0.8480\n",
      "\n",
      "Epoch 41/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8576\n",
      "Validaton loss: 0.8551\n",
      "\n",
      "Epoch 42/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8562\n",
      "Validaton loss: 0.8584\n",
      "\n",
      "Epoch 43/200\n",
      "Learning rate: 0.0001\n",
      "Training loss: 0.8517\n",
      "Validaton loss: 0.8557\n",
      "\n",
      "Epoch 44/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8524\n",
      "Validaton loss: 0.8421\n",
      "\n",
      "Epoch 45/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8492\n",
      "Validaton loss: 0.8438\n",
      "\n",
      "Epoch 46/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8590\n",
      "Validaton loss: 0.8641\n",
      "\n",
      "Epoch 47/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8526\n",
      "Validaton loss: 0.8427\n",
      "\n",
      "Epoch 48/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8516\n",
      "Validaton loss: 0.8407\n",
      "\n",
      "Epoch 49/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8503\n",
      "Validaton loss: 0.8483\n",
      "\n",
      "Epoch 50/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8484\n",
      "Validaton loss: 0.8416\n",
      "\n",
      "Epoch 51/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8549\n",
      "Validaton loss: 0.8429\n",
      "\n",
      "Epoch 52/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8528\n",
      "Validaton loss: 0.8437\n",
      "\n",
      "Epoch 53/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8524\n",
      "Validaton loss: 0.8384\n",
      "\n",
      "Epoch 54/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8573\n",
      "Validaton loss: 0.8424\n",
      "\n",
      "Epoch 55/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8643\n",
      "Validaton loss: 0.8460\n",
      "\n",
      "Epoch 56/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8614\n",
      "Validaton loss: 0.8371\n",
      "\n",
      "Epoch 57/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8552\n",
      "Validaton loss: 0.8422\n",
      "\n",
      "Epoch 58/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8549\n",
      "Validaton loss: 0.8799\n",
      "\n",
      "Epoch 59/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8572\n",
      "Validaton loss: 0.8472\n",
      "\n",
      "Epoch 60/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8554\n",
      "Validaton loss: 0.9291\n",
      "\n",
      "Epoch 61/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8520\n",
      "Validaton loss: 0.8409\n",
      "\n",
      "Epoch 62/200\n",
      "Learning rate: 1e-05\n",
      "Training loss: 0.8575\n",
      "Validaton loss: 0.9107\n",
      "\n",
      "Epoch 63/200\n",
      "Learning rate: 1.0000000000000002e-06\n",
      "Training loss: 0.8490\n",
      "Validaton loss: 0.8472\n",
      "\n",
      "Epoch 64/200\n",
      "Learning rate: 1.0000000000000002e-06\n",
      "Training loss: 0.8512\n",
      "Validaton loss: 0.8582\n",
      "\n",
      "Epoch 65/200\n",
      "Learning rate: 1.0000000000000002e-06\n",
      "Training loss: 0.8512\n",
      "Validaton loss: 0.8476\n",
      "\n",
      "Epoch 66/200\n",
      "Learning rate: 1.0000000000000002e-06\n",
      "Training loss: 0.8503\n",
      "Validaton loss: 0.8430\n",
      "\n",
      "Training stopped.\n"
     ]
    }
   ],
   "source": [
    "train_model(rnn, train_dataloader, valid_dataloader, learning_rate=1e-3, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trann\\AppData\\Local\\Temp\\ipykernel_17832\\3502257146.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2 = torch.load(\"models/gru.pth\", map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "model2 = torch.load(\"models/gru.pth\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[722.55963  ,  12.653603 ,  40.97966  ,   6.790102 ,  38.94258  ,\n",
       "         48.295567 ],\n",
       "       [701.9567   ,  11.765413 ,  48.14765  ,   6.446836 ,  41.225105 ,\n",
       "         51.398045 ],\n",
       "       [727.20746  ,  12.58371  ,  50.10069  ,   6.74116  ,  46.508232 ,\n",
       "         57.371773 ],\n",
       "       [776.70374  ,  14.11566  ,  44.83048  ,   7.3253865,  51.7511   ,\n",
       "         62.26421  ],\n",
       "       [747.1033   ,  13.628213 ,  47.47578  ,   7.779663 ,  50.048992 ,\n",
       "         59.623367 ],\n",
       "       [655.53156  ,  11.22266  ,  63.203033 ,   7.8397455,  45.765095 ,\n",
       "         55.338062 ],\n",
       "       [512.5292   ,   7.4163933,  74.705185 ,   6.492961 ,  30.349098 ,\n",
       "         37.803146 ],\n",
       "       [486.23657  ,   6.900783 ,  75.640236 ,   6.2612076,  26.937916 ,\n",
       "         33.39043  ],\n",
       "       [504.06067  ,   7.7272887,  77.22731  ,   7.3482122,  31.25623  ,\n",
       "         37.33813  ],\n",
       "       [505.781    ,   8.433699 ,  73.649185 ,   7.608622 ,  31.031166 ,\n",
       "         36.00131  ],\n",
       "       [486.4529   ,   8.433535 ,  72.56685  ,   7.6560373,  28.707344 ,\n",
       "         32.729347 ],\n",
       "       [483.89075  ,   8.5824375,  71.88846  ,   7.74577  ,  28.050125 ,\n",
       "         31.678894 ],\n",
       "       [489.1654   ,   8.695648 ,  73.08506  ,   7.965047 ,  29.34304  ,\n",
       "         33.008633 ],\n",
       "       [508.49203  ,   9.45481  ,  68.13699  ,   7.9310226,  28.831722 ,\n",
       "         32.25196  ],\n",
       "       [596.6876   ,  12.301927 ,  54.85547  ,   8.460635 ,  32.302097 ,\n",
       "         36.443893 ],\n",
       "       [685.28296  ,  14.757477 ,  42.941277 ,   8.865329 ,  35.562855 ,\n",
       "         41.128437 ],\n",
       "       [683.17065  ,  14.488807 ,  41.272076 ,   8.749474 ,  33.906925 ,\n",
       "         40.080593 ],\n",
       "       [686.4347   ,  14.017309 ,  41.36693  ,   8.545828 ,  35.300423 ,\n",
       "         42.206406 ],\n",
       "       [677.78357  ,  13.705767 ,  39.797554 ,   8.292906 ,  33.517807 ,\n",
       "         40.476727 ],\n",
       "       [694.2523   ,  14.345168 ,  36.165028 ,   8.194035 ,  31.872663 ,\n",
       "         38.726738 ],\n",
       "       [725.57465  ,  14.8484955,  31.973341 ,   8.144112 ,  32.974792 ,\n",
       "         39.991726 ],\n",
       "       [740.0426   ,  14.953086 ,  29.234528 ,   8.050289 ,  33.02958  ,\n",
       "         39.94706  ],\n",
       "       [754.1638   ,  14.877082 ,  26.20309  ,   7.829908 ,  33.346382 ,\n",
       "         40.140858 ],\n",
       "       [753.18646  ,  14.693205 ,  24.952293 ,   7.7245493,  32.585094 ,\n",
       "         39.044518 ],\n",
       "       [742.31824  ,  14.476989 ,  26.364874 ,   7.898297 ,  32.623894 ,\n",
       "         38.7829   ],\n",
       "       [732.7505   ,  14.364727 ,  28.1236   ,   8.093417 ,  33.27731  ,\n",
       "         39.55296  ],\n",
       "       [731.48364  ,  14.616838 ,  30.02694  ,   8.215679 ,  34.15407  ,\n",
       "         40.937244 ],\n",
       "       [741.15497  ,  14.9077   ,  30.463976 ,   8.215493 ,  35.436516 ,\n",
       "         42.5495   ],\n",
       "       [745.67896  ,  14.890995 ,  30.103363 ,   8.185994 ,  36.025593 ,\n",
       "         43.112164 ],\n",
       "       [740.27936  ,  14.698637 ,  30.22952  ,   8.13976  ,  35.621147 ,\n",
       "         42.517456 ],\n",
       "       [718.0427   ,  14.364416 ,  32.226124 ,   8.243576 ,  33.921204 ,\n",
       "         40.561504 ],\n",
       "       [683.0595   ,  13.771049 ,  35.64377  ,   8.250118 ,  31.364346 ,\n",
       "         37.77019  ],\n",
       "       [635.7269   ,  12.764834 ,  39.715683 ,   7.9950166,  27.69154  ,\n",
       "         33.811375 ],\n",
       "       [564.45074  ,  10.900133 ,  47.42347  ,   7.4378014,  23.044209 ,\n",
       "         28.756899 ],\n",
       "       [493.62238  ,   8.945335 ,  52.694805 ,   6.501817 ,  17.389553 ,\n",
       "         22.605453 ],\n",
       "       [491.8811   ,   8.944145 ,  51.268738 ,   6.1025395,  17.259956 ,\n",
       "         22.37199  ],\n",
       "       [543.7233   ,  10.639985 ,  48.163895 ,   6.864646 ,  21.67688  ,\n",
       "         26.822866 ],\n",
       "       [608.95764  ,  12.569445 ,  43.312263 ,   7.701037 ,  26.138565 ,\n",
       "         31.871208 ],\n",
       "       [666.4144   ,  13.925709 ,  38.052822 ,   8.090301 ,  29.645164 ,\n",
       "         36.162357 ],\n",
       "       [724.3566   ,  14.941861 ,  32.48592  ,   8.1775055,  33.33836  ,\n",
       "         40.477177 ],\n",
       "       [754.5029   ,  15.147509 ,  29.209972 ,   8.102647 ,  35.69296  ,\n",
       "         42.89649  ],\n",
       "       [760.3223   ,  14.976371 ,  27.21975  ,   7.9530363,  35.467358 ,\n",
       "         42.412514 ],\n",
       "       [756.30383  ,  14.739542 ,  26.18773  ,   7.8793254,  34.624817 ,\n",
       "         41.286694 ],\n",
       "       [753.867    ,  14.699146 ,  25.727308 ,   7.828141 ,  33.68007  ,\n",
       "         40.20936  ],\n",
       "       [753.89087  ,  14.630283 ,  24.89256  ,   7.7635083,  33.175514 ,\n",
       "         39.627247 ],\n",
       "       [759.3225   ,  14.632299 ,  24.253845 ,   7.68152  ,  33.558075 ,\n",
       "         40.020622 ],\n",
       "       [760.9242   ,  14.496653 ,  23.41362  ,   7.5747375,  33.41063  ,\n",
       "         39.71467  ],\n",
       "       [762.56116  ,  14.419302 ,  22.9963   ,   7.534117 ,  33.67212  ,\n",
       "         39.876225 ],\n",
       "       [765.5982   ,  14.41123  ,  22.64186  ,   7.4781184,  33.89722  ,\n",
       "         40.168278 ],\n",
       "       [770.2804   ,  14.313376 ,  22.450922 ,   7.3725753,  34.73835  ,\n",
       "         41.138153 ],\n",
       "       [773.4028   ,  14.223148 ,  22.256987 ,   7.3035975,  35.53025  ,\n",
       "         41.910065 ],\n",
       "       [770.80615  ,  14.1432085,  22.054504 ,   7.281328 ,  35.12539  ,\n",
       "         41.336777 ],\n",
       "       [765.436    ,  14.17308  ,  23.851723 ,   7.5076323,  35.839577 ,\n",
       "         42.006256 ],\n",
       "       [750.9348   ,  14.236895 ,  27.015802 ,   7.922114 ,  36.227776 ,\n",
       "         42.51104  ],\n",
       "       [711.4474   ,  13.834215 ,  34.25725  ,   8.303652 ,  35.317337 ,\n",
       "         41.956123 ],\n",
       "       [632.4901   ,  12.1641655,  44.931644 ,   7.9985275,  30.63176  ,\n",
       "         37.20334  ],\n",
       "       [571.0416   ,  10.715598 ,  51.3563   ,   7.363242 ,  26.03188  ,\n",
       "         32.414562 ],\n",
       "       [561.7612   ,  10.644731 ,  55.051224 ,   7.453406 ,  27.197126 ,\n",
       "         33.299423 ],\n",
       "       [552.1226   ,  10.564226 ,  57.65744  ,   7.710121 ,  27.685772 ,\n",
       "         33.383583 ],\n",
       "       [570.97675  ,  11.272112 ,  53.76966  ,   7.7746177,  28.278301 ,\n",
       "         33.909702 ],\n",
       "       [629.88776  ,  13.085309 ,  44.696102 ,   8.051839 ,  29.847137 ,\n",
       "         35.78595  ],\n",
       "       [676.38855  ,  14.244419 ,  39.459446 ,   8.37754  ,  31.749182 ,\n",
       "         38.160835 ],\n",
       "       [702.9851   ,  14.639329 ,  36.51266  ,   8.428988 ,  33.334377 ,\n",
       "         40.238266 ],\n",
       "       [743.1901   ,  15.113675 ,  31.832035 ,   8.2916565,  36.216434 ,\n",
       "         43.640305 ],\n",
       "       [751.6484   ,  15.092796 ,  30.193142 ,   8.156874 ,  36.123726 ,\n",
       "         43.29729  ],\n",
       "       [737.03937  ,  14.657342 ,  29.559082 ,   8.05252  ,  33.747658 ,\n",
       "         40.36696  ],\n",
       "       [724.5275   ,  14.390699 ,  28.148842 ,   7.962439 ,  31.2893   ,\n",
       "         37.63295  ],\n",
       "       [727.9235   ,  14.639502 ,  27.362938 ,   7.896909 ,  30.22586  ,\n",
       "         36.744194 ],\n",
       "       [761.3097   ,  14.954567 ,  24.969343 ,   7.732793 ,  33.266796 ,\n",
       "         40.174095 ],\n",
       "       [785.0424   ,  14.91389  ,  23.894466 ,   7.5713754,  36.85759  ,\n",
       "         43.97877  ],\n",
       "       [803.7389   ,  14.751701 ,  22.498592 ,   7.2324953,  39.49069  ,\n",
       "         46.94131  ],\n",
       "       [802.299    ,  14.24832  ,  21.694477 ,   6.8944464,  39.567112 ,\n",
       "         47.009415 ],\n",
       "       [793.5424   ,  13.934175 ,  21.366585 ,   6.773265 ,  38.390694 ,\n",
       "         45.227337 ],\n",
       "       [775.0469   ,  13.677507 ,  22.341858 ,   7.042015 ,  37.320297 ,\n",
       "         43.30543  ],\n",
       "       [769.7475   ,  14.16194  ,  23.823868 ,   7.439219 ,  36.574966 ,\n",
       "         42.728416 ],\n",
       "       [772.0803   ,  14.57543  ,  24.516155 ,   7.7120743,  36.94696  ,\n",
       "         43.622917 ],\n",
       "       [787.61206  ,  14.912908 ,  24.964022 ,   7.7398987,  39.308853 ,\n",
       "         46.5248   ],\n",
       "       [789.5481   ,  14.9383335,  26.611664 ,   7.9040017,  41.40724  ,\n",
       "         48.65322  ],\n",
       "       [784.5544   ,  15.096417 ,  28.724909 ,   8.192634 ,  42.210274 ,\n",
       "         49.59579  ],\n",
       "       [771.47455  ,  15.207779 ,  31.631096 ,   8.500587 ,  41.939335 ,\n",
       "         49.512165 ],\n",
       "       [748.6943   ,  14.838476 ,  38.739704 ,   8.662534 ,  43.044083 ,\n",
       "         51.275116 ],\n",
       "       [659.445    ,  12.144387 ,  51.449776 ,   7.923839 ,  37.930305 ,\n",
       "         45.965927 ],\n",
       "       [554.96844  ,   9.430778 ,  57.263012 ,   6.582103 ,  26.061829 ,\n",
       "         32.803947 ],\n",
       "       [527.2346   ,   8.825125 ,  60.24654  ,   6.377988 ,  24.605007 ,\n",
       "         31.133904 ],\n",
       "       [531.2433   ,   9.427441 ,  57.99266  ,   6.6268754,  24.447758 ,\n",
       "         30.245487 ],\n",
       "       [552.8455   ,  10.619917 ,  49.925323 ,   6.82221  ,  23.03621  ,\n",
       "         28.421413 ],\n",
       "       [607.1944   ,  12.317656 ,  45.881123 ,   7.6473494,  27.019924 ,\n",
       "         32.814457 ],\n",
       "       [663.8498   ,  13.738927 ,  39.241947 ,   7.9573298,  29.713367 ,\n",
       "         36.233585 ],\n",
       "       [697.4964   ,  14.3197   ,  36.19514  ,   8.173746 ,  32.043137 ,\n",
       "         38.864594 ],\n",
       "       [721.24316  ,  14.629919 ,  34.037292 ,   8.13892  ,  33.685986 ,\n",
       "         40.990707 ],\n",
       "       [744.95636  ,  14.738259 ,  32.35257  ,   7.889322 ,  35.968876 ,\n",
       "         44.03834  ],\n",
       "       [775.7066   ,  14.872406 ,  31.19777  ,   7.4885774,  39.44172  ,\n",
       "         48.16026  ],\n",
       "       [806.8068   ,  14.717043 ,  29.285515 ,   6.958192 ,  44.038128 ,\n",
       "         53.48976  ],\n",
       "       [822.3994   ,  14.558582 ,  27.426308 ,   6.45699  ,  45.20588  ,\n",
       "         55.099667 ],\n",
       "       [833.7145   ,  14.218943 ,  23.776936 ,   5.944026 ,  45.096104 ,\n",
       "         54.60188  ],\n",
       "       [845.3544   ,  13.896057 ,  21.452671 ,   5.742406 ,  47.24681  ,\n",
       "         55.8303   ],\n",
       "       [844.95166  ,  13.672067 ,  21.224821 ,   5.8519487,  48.6962   ,\n",
       "         56.68577  ],\n",
       "       [832.71686  ,  13.755271 ,  26.117548 ,   6.437081 ,  50.749573 ,\n",
       "         59.78626  ],\n",
       "       [841.39685  ,  14.203402 ,  28.479906 ,   6.54031  ,  53.446392 ,\n",
       "         64.02356  ],\n",
       "       [866.24133  ,  14.883182 ,  29.810846 ,   6.438086 ,  57.534134 ,\n",
       "         69.22088  ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict((weather_np[:100], init_np[:100]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
